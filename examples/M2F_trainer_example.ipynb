{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\absolute-zero\\Desktop\\NNIS\\examples\\Mask2Former')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create directories for data\n",
    "os.makedirs('data/train_images', exist_ok=True)\n",
    "os.makedirs('data/val_images', exist_ok=True)\n",
    "os.makedirs('data/annotations', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 87.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 70.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate synthetic dataset\n",
    "def create_synthetic_dataset(num_images, image_dir, annotation_file):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    annotation_id = 1\n",
    "\n",
    "    for img_id in tqdm(range(1, num_images + 1)):\n",
    "        # Create a random image\n",
    "        image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "        img = Image.fromarray(image)\n",
    "        img_filename = f'image_{img_id}.png'\n",
    "        img.save(os.path.join(image_dir, img_filename))\n",
    "\n",
    "        # Create a random mask with a simple shape\n",
    "        mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "        cv2.rectangle(mask, (60, 60), (196, 196), 1, -1)  # Draw a filled rectangle\n",
    "        mask_image = Image.fromarray(mask * 255)\n",
    "        mask_filename = f'mask_{img_id}.png'\n",
    "        mask_image.save(os.path.join(image_dir, mask_filename))\n",
    "\n",
    "        # Create segmentation polygon for the rectangle\n",
    "        segmentation = [[60, 60, 196, 60, 196, 196, 60, 196]]\n",
    "        area = 136 * 136  # Area of the rectangle\n",
    "        bbox = [60, 60, 136, 136]  # x, y, width, height\n",
    "\n",
    "        # Image info\n",
    "        images.append({\n",
    "            'file_name': img_filename,\n",
    "            'height': 256,\n",
    "            'width': 256,\n",
    "            'id': img_id\n",
    "        })\n",
    "\n",
    "        # Annotation info\n",
    "        annotations.append({\n",
    "            'id': annotation_id,\n",
    "            'image_id': img_id,\n",
    "            'category_id': 1,\n",
    "            'segmentation': segmentation,\n",
    "            'area': area,\n",
    "            'bbox': bbox,\n",
    "            'iscrowd': 0\n",
    "        })\n",
    "\n",
    "        annotation_id += 1\n",
    "\n",
    "    # Categories\n",
    "    categories = [{\n",
    "        'id': 1,\n",
    "        'name': 'rectangle',\n",
    "        'supercategory': 'shape'\n",
    "    }]\n",
    "\n",
    "    # Create annotation file in COCO format\n",
    "    annotation_data = {\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    with open(annotation_file, 'w') as f:\n",
    "        json.dump(annotation_data, f)\n",
    "\n",
    "# Create training data\n",
    "create_synthetic_dataset(10, 'data/train_images', 'data/annotations/instances_train.json')\n",
    "\n",
    "# Create validation data\n",
    "create_synthetic_dataset(2, 'data/val_images', 'data/annotations/instances_val.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Register datasets with Detectron2\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"synthetic_train\", {}, \"data/annotations/instances_train.json\", \"data/train_images\")\n",
    "register_coco_instances(\"synthetic_val\", {}, \"data/annotations/instances_val.json\", \"data/val_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "\n\nPlease compile MultiScaleDeformableAttention CUDA op with the following commands:\n\t`cd mask2former/modeling/pixel_decoder/ops`\n\t`sh make.sh`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\ops\\functions\\ms_deform_attn_func.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMultiScaleDeformableAttention\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mMSDA\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'MultiScaleDeformableAttention'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cfg\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmask2former\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_maskformer2_config\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultTrainer\n\u001b[0;32m      7\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data  \u001b[38;5;66;03m# register all new datasets\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m modeling\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# config\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_maskformer2_config\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m D2SwinTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpixel_decoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfpn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePixelDecoder\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpixel_decoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdeformattn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttnPixelDecoder\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_arch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask_former_head\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskFormerHead\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_arch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mper_pixel_baseline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PerPixelBaselineHead, PerPixelBaselinePlusHead\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\msdeformattn.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_decoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mposition_encoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PositionEmbeddingSine\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_decoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_clones, _get_activation_fn\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttn\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# MSDeformAttn Transformer encoder in deformable detr\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMSDeformAttnTransformerEncoderOnly\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\ops\\modules\\__init__.py:12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Deformable DETR\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2020 SenseTime. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Modified by Bowen Cheng from https://github.com/fundamentalvision/Deformable-DETR\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_deform_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttn\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\ops\\modules\\ms_deform_attn.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xavier_uniform_, constant_\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttnFunction\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_deform_attn_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ms_deform_attn_core_pytorch\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_power_of_2\u001b[39m(n):\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\ops\\functions\\__init__.py:12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Deformable DETR\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2020 SenseTime. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Modified by Bowen Cheng from https://github.com/fundamentalvision/Deformable-DETR\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_deform_attn_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttnFunction\n",
      "File \u001b[1;32m~\\Desktop\\NNIS\\examples\\Mask2Former\\mask2former\\modeling\\pixel_decoder\\ops\\functions\\ms_deform_attn_func.py:29\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     24\u001b[0m     info_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease compile MultiScaleDeformableAttention CUDA op with the following commands:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m`cd mask2former/modeling/pixel_decoder/ops`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m`sh make.sh`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(info_string)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMSDeformAttnFunction\u001b[39;00m(Function):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, value, value_spatial_shapes, value_level_start_index, sampling_locations, attention_weights, im2col_step):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: \n\nPlease compile MultiScaleDeformableAttention CUDA op with the following commands:\n\t`cd mask2former/modeling/pixel_decoder/ops`\n\t`sh make.sh`\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Configure the Mask2Former model\n",
    "import detectron2\n",
    "from detectron2.config import get_cfg\n",
    "from mask2former import add_maskformer2_config\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_maskformer2_config(cfg)\n",
    "\n",
    "cfg.merge_from_file(\"Mask2Former/configs/coco/instance-segmentation/maskformer2_R50_bs16_50ep.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"synthetic_train\",)\n",
    "cfg.DATASETS.TEST = (\"synthetic_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 1\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./output_synthetic\"\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Train the model\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Save the model path\n",
    "model_weights_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "print(f\"Model weights saved to: {model_weights_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Run inference to verify the model\n",
    "import cv2\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_weights_path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.DATASETS.TEST = (\"synthetic_val\", )\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "image = cv2.imread(\"data/val_images/image_1.png\")\n",
    "outputs = predictor(image)\n",
    "\n",
    "v = Visualizer(image[:, :, ::-1], scale=1.0)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "result_image = v.get_image()[:, :, ::-1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
