{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apd/miniconda3/envs/NNIS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'predictor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmask2former\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_maskformer2_config\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisualizationDemo\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# constants\u001b[39;00m\n\u001b[1;32m     31\u001b[0m WINDOW_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask2former demo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'predictor'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# Modified by Bowen Cheng from: https://github.com/facebookresearch/detectron2/blob/master/demo/demo.py\n",
    "import argparse\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "# fmt: off\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "# fmt: on\n",
    "\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "from mask2former import add_maskformer2_config\n",
    "from predictor import VisualizationDemo\n",
    "\n",
    "\n",
    "# constants\n",
    "WINDOW_NAME = \"mask2former demo\"\n",
    "\n",
    "\n",
    "def setup_cfg(args):\n",
    "    # load config from file and command-line arguments\n",
    "    cfg = get_cfg()\n",
    "    add_deeplab_config(cfg)\n",
    "    add_maskformer2_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"maskformer2 demo for builtin configs\")\n",
    "    parser.add_argument(\n",
    "        \"--config-file\",\n",
    "        default=\"configs/coco/panoptic-segmentation/maskformer2_R50_bs16_50ep.yaml\",\n",
    "        metavar=\"FILE\",\n",
    "        help=\"path to config file\",\n",
    "    )\n",
    "    parser.add_argument(\"--webcam\", action=\"store_true\", help=\"Take inputs from webcam.\")\n",
    "    parser.add_argument(\"--video-input\", help=\"Path to video file.\")\n",
    "    parser.add_argument(\n",
    "        \"--input\",\n",
    "        nargs=\"+\",\n",
    "        help=\"A list of space separated input images; \"\n",
    "        \"or a single glob pattern such as 'directory/*.jpg'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        help=\"A file or directory to save output visualizations. \"\n",
    "        \"If not given, will show output in an OpenCV window.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--confidence-threshold\",\n",
    "        type=float,\n",
    "        default=0.5,\n",
    "        help=\"Minimum score for instance predictions to be shown\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options using the command-line 'KEY VALUE' pairs\",\n",
    "        default=[],\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def test_opencv_video_format(codec, file_ext):\n",
    "    with tempfile.TemporaryDirectory(prefix=\"video_format_test\") as dir:\n",
    "        filename = os.path.join(dir, \"test_file\" + file_ext)\n",
    "        writer = cv2.VideoWriter(\n",
    "            filename=filename,\n",
    "            fourcc=cv2.VideoWriter_fourcc(*codec),\n",
    "            fps=float(30),\n",
    "            frameSize=(10, 10),\n",
    "            isColor=True,\n",
    "        )\n",
    "        [writer.write(np.zeros((10, 10, 3), np.uint8)) for _ in range(30)]\n",
    "        writer.release()\n",
    "        if os.path.isfile(filename):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    args = get_parser().parse_args()\n",
    "    setup_logger(name=\"fvcore\")\n",
    "    logger = setup_logger()\n",
    "    logger.info(\"Arguments: \" + str(args))\n",
    "\n",
    "    cfg = setup_cfg(args)\n",
    "\n",
    "    demo = VisualizationDemo(cfg)\n",
    "\n",
    "    if args.input:\n",
    "        if len(args.input) == 1:\n",
    "            args.input = glob.glob(os.path.expanduser(args.input[0]))\n",
    "            assert args.input, \"The input path(s) was not found\"\n",
    "        for path in tqdm.tqdm(args.input, disable=not args.output):\n",
    "            # use PIL, to be consistent with evaluation\n",
    "            img = read_image(path, format=\"BGR\")\n",
    "            start_time = time.time()\n",
    "            predictions, visualized_output = demo.run_on_image(img)\n",
    "            logger.info(\n",
    "                \"{}: {} in {:.2f}s\".format(\n",
    "                    path,\n",
    "                    \"detected {} instances\".format(len(predictions[\"instances\"]))\n",
    "                    if \"instances\" in predictions\n",
    "                    else \"finished\",\n",
    "                    time.time() - start_time,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if args.output:\n",
    "                if os.path.isdir(args.output):\n",
    "                    assert os.path.isdir(args.output), args.output\n",
    "                    out_filename = os.path.join(args.output, os.path.basename(path))\n",
    "                else:\n",
    "                    assert len(args.input) == 1, \"Please specify a directory with args.output\"\n",
    "                    out_filename = args.output\n",
    "                visualized_output.save(out_filename)\n",
    "            else:\n",
    "                cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "                cv2.imshow(WINDOW_NAME, visualized_output.get_image()[:, :, ::-1])\n",
    "                if cv2.waitKey(0) == 27:\n",
    "                    break  # esc to quit\n",
    "    elif args.webcam:\n",
    "        assert args.input is None, \"Cannot have both --input and --webcam!\"\n",
    "        assert args.output is None, \"output not yet supported with --webcam!\"\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        for vis in tqdm.tqdm(demo.run_on_video(cam)):\n",
    "            cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(WINDOW_NAME, vis)\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break  # esc to quit\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    elif args.video_input:\n",
    "        video = cv2.VideoCapture(args.video_input)\n",
    "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "        num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        basename = os.path.basename(args.video_input)\n",
    "        codec, file_ext = (\n",
    "            (\"x264\", \".mkv\") if test_opencv_video_format(\"x264\", \".mkv\") else (\"mp4v\", \".mp4\")\n",
    "        )\n",
    "        if codec == \".mp4v\":\n",
    "            warnings.warn(\"x264 codec not available, switching to mp4v\")\n",
    "        if args.output:\n",
    "            if os.path.isdir(args.output):\n",
    "                output_fname = os.path.join(args.output, basename)\n",
    "                output_fname = os.path.splitext(output_fname)[0] + file_ext\n",
    "            else:\n",
    "                output_fname = args.output\n",
    "            assert not os.path.isfile(output_fname), output_fname\n",
    "            output_file = cv2.VideoWriter(\n",
    "                filename=output_fname,\n",
    "                # some installation of opencv may not support x264 (due to its license),\n",
    "                # you can try other format (e.g. MPEG)\n",
    "                fourcc=cv2.VideoWriter_fourcc(*codec),\n",
    "                fps=float(frames_per_second),\n",
    "                frameSize=(width, height),\n",
    "                isColor=True,\n",
    "            )\n",
    "        assert os.path.isfile(args.video_input)\n",
    "        for vis_frame in tqdm.tqdm(demo.run_on_video(video), total=num_frames):\n",
    "            if args.output:\n",
    "                output_file.write(vis_frame)\n",
    "            else:\n",
    "                cv2.namedWindow(basename, cv2.WINDOW_NORMAL)\n",
    "                cv2.imshow(basename, vis_frame)\n",
    "                if cv2.waitKey(1) == 27:\n",
    "                    break  # esc to quit\n",
    "        video.release()\n",
    "        if args.output:\n",
    "            output_file.release()\n",
    "        else:\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\absolute-zero\\Desktop\\NNIS\\examples\\Mask2Former')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create directories for data\n",
    "os.makedirs('data/train_images', exist_ok=True)\n",
    "os.makedirs('data/val_images', exist_ok=True)\n",
    "os.makedirs('data/annotations', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 110.53it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 118.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate synthetic dataset\n",
    "def create_synthetic_dataset(num_images, image_dir, annotation_file):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    annotation_id = 1\n",
    "\n",
    "    for img_id in tqdm(range(1, num_images + 1)):\n",
    "        # Create a random image\n",
    "        image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "        img = Image.fromarray(image)\n",
    "        img_filename = f'image_{img_id}.png'\n",
    "        img.save(os.path.join(image_dir, img_filename))\n",
    "\n",
    "        # Create a random mask with a simple shape\n",
    "        mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "        cv2.rectangle(mask, (60, 60), (196, 196), 1, -1)  # Draw a filled rectangle\n",
    "        mask_image = Image.fromarray(mask * 255)\n",
    "        mask_filename = f'mask_{img_id}.png'\n",
    "        mask_image.save(os.path.join(image_dir, mask_filename))\n",
    "\n",
    "        # Create segmentation polygon for the rectangle\n",
    "        segmentation = [[60, 60, 196, 60, 196, 196, 60, 196]]\n",
    "        area = 136 * 136  # Area of the rectangle\n",
    "        bbox = [60, 60, 136, 136]  # x, y, width, height\n",
    "\n",
    "        # Image info\n",
    "        images.append({\n",
    "            'file_name': img_filename,\n",
    "            'height': 256,\n",
    "            'width': 256,\n",
    "            'id': img_id\n",
    "        })\n",
    "\n",
    "        # Annotation info\n",
    "        annotations.append({\n",
    "            'id': annotation_id,\n",
    "            'image_id': img_id,\n",
    "            'category_id': 1,\n",
    "            'segmentation': segmentation,\n",
    "            'area': area,\n",
    "            'bbox': bbox,\n",
    "            'iscrowd': 0\n",
    "        })\n",
    "\n",
    "        annotation_id += 1\n",
    "\n",
    "    # Categories\n",
    "    categories = [{\n",
    "        'id': 1,\n",
    "        'name': 'rectangle',\n",
    "        'supercategory': 'shape'\n",
    "    }]\n",
    "\n",
    "    # Create annotation file in COCO format\n",
    "    annotation_data = {\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    with open(annotation_file, 'w') as f:\n",
    "        json.dump(annotation_data, f)\n",
    "\n",
    "# Create training data~\n",
    "create_synthetic_dataset(10, 'data/train_images', 'data/annotations/instances_train.json')\n",
    "\n",
    "# Create validation data\n",
    "create_synthetic_dataset(2, 'data/val_images', 'data/annotations/instances_val.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apd/miniconda3/envs/NNIS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Register datasets with Detectron2\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"synthetic_train\", {}, \"data/annotations/instances_train.json\", \"data/train_images\")\n",
    "register_coco_instances(\"synthetic_val\", {}, \"data/annotations/instances_val.json\", \"data/val_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Non-existent config key: MODEL.RESNETS.STEM_TYPE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[1;32m      8\u001b[0m add_maskformer2_config(cfg)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/apd/NNIS/Mask2Former/configs/coco/instance-segmentation/maskformer2_R50_bs16_50ep.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTRAIN \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthetic_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m     13\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthetic_val\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/detectron2/config/config.py:69\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[0;34m(self, cfg_filename, allow_unsafe)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m loaded_ver \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVERSION, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot merge a v\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m config into a v\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m config.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     65\u001b[0m     loaded_ver, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVERSION\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loaded_ver \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVERSION:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_other_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# compat.py needs to import CfgNode\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upgrade_config, downgrade_config\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/fvcore/common/config.py:132\u001b[0m, in \u001b[0;36mCfgNode.merge_from_other_cfg\u001b[0;34m(self, cfg_other)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    cfg_other (CfgNode): configs to merge from.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    130\u001b[0m     BASE_KEY \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cfg_other\n\u001b[1;32m    131\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe reserved key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only be used in files!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(BASE_KEY)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_other_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_other\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/yacs/config.py:217\u001b[0m, in \u001b[0;36mCfgNode.merge_from_other_cfg\u001b[0;34m(self, cfg_other)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_from_other_cfg\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_other):\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Merge `cfg_other` into this CfgNode.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/yacs/config.py:478\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[0;34m(a, b, root, key_list)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, CfgNode):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/yacs/config.py:478\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[0;34m(a, b, root, key_list)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, CfgNode):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NNIS/lib/python3.9/site-packages/yacs/config.py:491\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[0;34m(a, b, root, key_list)\u001b[0m\n\u001b[1;32m    489\u001b[0m     root\u001b[38;5;241m.\u001b[39mraise_key_rename_error(full_key)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-existent config key: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(full_key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Non-existent config key: MODEL.RESNETS.STEM_TYPE'"
     ]
    }
   ],
   "source": [
    "# Step 8: Configure the Mask2Former model\n",
    "import detectron2\n",
    "from detectron2.config import get_cfg\n",
    "from mask2former import add_maskformer2_config\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_maskformer2_config(cfg)\n",
    "\n",
    "cfg.merge_from_file(\"/home/apd/NNIS/Mask2Former/configs/coco/instance-segmentation/maskformer2_R50_bs16_50ep.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"synthetic_train\",)\n",
    "cfg.DATASETS.TEST = (\"synthetic_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 1\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./output_synthetic\"\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Train the model\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Save the model path\n",
    "model_weights_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "print(f\"Model weights saved to: {model_weights_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Run inference to verify the model\n",
    "import cv2\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_weights_path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.DATASETS.TEST = (\"synthetic_val\", )\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "image = cv2.imread(\"data/val_images/image_1.png\")\n",
    "outputs = predictor(image)\n",
    "\n",
    "v = Visualizer(image[:, :, ::-1], scale=1.0)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "result_image = v.get_image()[:, :, ::-1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
